{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73abf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup\n",
    "from df2gspread import df2gspread as d2g\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "\n",
    "# Suprime todos os warnings para uma saída mais limpa\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31de3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURAÇÕES GERAIS (carregadas a partir do arquivo .env)\n",
    "# ==============================================================================\n",
    "# --- Credenciais e Acessos ---\n",
    "SUNO_USERNAME = os.getenv('SUNO_USERNAME')\n",
    "SUNO_PASSWORD = os.getenv('SUNO_PASSWORD')\n",
    "BRAPI_TOKEN = os.getenv('BRAPI_TOKEN')\n",
    "GOOGLE_SHEETS_KEY = os.getenv('GOOGLE_SHEETS_KEY')\n",
    "\n",
    "# --- Caminhos de Arquivos e Nomes ---\n",
    "PARQUET_FILE_PATH = os.getenv('PARQUET_FILE_PATH')\n",
    "GSPREAD_CREDENTIALS_PATH = os.getenv('GSPREAD_CREDENTIALS_PATH')\n",
    "GSHEET_WORKSHEET_NAME = 'Carteira_Suno'\n",
    "\n",
    "# --- URLs e Endpoints ---\n",
    "SUNO_LOGIN_URL = 'https://login.suno.com.br/entrar/cef02de7-1e5a-4b0e-9f41-04e9278aa2d7/'\n",
    "SUNO_FIIS_URL = 'https://investidor.suno.com.br/carteiras/fiis'\n",
    "BRAPI_BASE_URL = 'https://brapi.dev/api/quote'\n",
    "\n",
    "# --- Configurações do Google API ---\n",
    "GSPREAD_SCOPES = [\n",
    "    'https://spreadsheets.google.com/feeds',\n",
    "    'https://www.googleapis.com/auth/drive',\n",
    "    'https://www.googleapis.com/auth/drive.file',\n",
    "    'https://www.googleapis.com/auth/spreadsheets'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ce1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_webdriver() -> webdriver.Chrome:\n",
    "    \"\"\"Configura e inicializa o WebDriver do Selenium.\"\"\"\n",
    "    sys.path.insert(0, \"/usr/lib/chromium-driver/chromedriver\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    arguments = [\n",
    "        '--headless', '--no-sandbox', '--disable-dev-shm-usage',\n",
    "        '--start-maximized', '--window-size=1920,1080', '--disable-gpu',\n",
    "        '--ignore-certificate-errors', '--disable-extensions',\n",
    "        'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'\n",
    "    ]\n",
    "    for arg in arguments:\n",
    "        chrome_options.add_argument(arg)\n",
    "        \n",
    "    return webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "def scrape_suno_portfolio(driver: webdriver.Chrome) -> pd.DataFrame:\n",
    "    \"\"\"Realiza o login no site da Suno e extrai os dados da carteira de FIIs.\"\"\"\n",
    "    print(\"Iniciando scraping da carteira Suno FIIs...\")\n",
    "    driver.get(SUNO_LOGIN_URL)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"user_email\"))).send_keys(SUNO_USERNAME)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"user_password\"))).send_keys(SUNO_PASSWORD)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"login_button\"))).click()\n",
    "    \n",
    "    WebDriverWait(driver, 25).until(EC.url_contains('home'))\n",
    "    driver.get(SUNO_FIIS_URL)\n",
    "    \n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'tbody.ant-table-tbody')))\n",
    "    time.sleep(2)  # Mantido para garantir a renderização completa da página.\n",
    "\n",
    "    html = driver.execute_script(\"return document.body.outerHTML;\")\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    table_body = soup.find('tbody')\n",
    "    if not table_body:\n",
    "        raise ValueError(\"Tabela de FIIs não encontrada na página.\")\n",
    "        \n",
    "    list_td = table_body.find_all('td')\n",
    "    \n",
    "    scraped_data = []\n",
    "    # A lógica de iteração (índices fixos) foi mantida para não alterar o resultado.\n",
    "    i = 11\n",
    "    step = i - 1\n",
    "    while True:\n",
    "        try:\n",
    "            fii = {\n",
    "                'ticker': list_td[i].text.replace('Ver relatórios', ''),\n",
    "                'setor/tipo': list_td[i+1].text,\n",
    "                'dy esperado': list_td[i+2].text,\n",
    "                'início': list_td[i+3].text[-10:],\n",
    "                'preço de entrada ajustado': list_td[i+3].text[:-10],\n",
    "                'preço atual': list_td[i+4].text.split(',')[0] + ',' + list_td[i+4].text.split(',')[1][:-1].replace('-', ''),\n",
    "                'preço teto': list_td[i+5].text,\n",
    "                'alocação': list_td[i+6].text,\n",
    "                'rentabilidade': list_td[i+7].text,\n",
    "                'viés': list_td[i+8].text\n",
    "            }\n",
    "            scraped_data.append(fii)\n",
    "            i += step\n",
    "        except IndexError:\n",
    "            break\n",
    "            \n",
    "    print(f\"Scraping finalizado. {len(scraped_data)} FIIs encontrados.\")\n",
    "    return pd.DataFrame(scraped_data)\n",
    "\n",
    "\n",
    "def fetch_historical_prices(tickers: list) -> pd.DataFrame:\n",
    "    \"\"\"Busca o histórico de preços para uma lista de tickers usando a API Brapi.\"\"\"\n",
    "    print(\"\\nIniciando a busca de dados históricos de cotações...\")\n",
    "    all_dataframes = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        url = f\"{BRAPI_BASE_URL}/{ticker}?range=1mo&interval=1d&token={BRAPI_TOKEN}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data_prices = response.json()\n",
    "            \n",
    "            historical_list = data_prices['results'][0]['historicalDataPrice']\n",
    "            df_fii = pd.DataFrame(historical_list)\n",
    "            df_fii['ticker'] = ticker\n",
    "            all_dataframes.append(df_fii)\n",
    "            print(f\" -> Sucesso! {len(df_fii)} registros encontrados para {ticker}.\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\" -> ERRO de requisição para {ticker}: {e}\")\n",
    "        except (KeyError, IndexError):\n",
    "            print(f\" -> ERRO: Ticker '{ticker}' não encontrado ou sem dados na API.\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    if not all_dataframes:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    hist_1m = pd.concat(all_dataframes, ignore_index=True)\n",
    "    hist_1m['date'] = pd.to_datetime(hist_1m['date'], unit='s').dt.date\n",
    "    \n",
    "    print(\"\\nDownload de dados históricos concluído!\")\n",
    "    return hist_1m[['ticker', 'date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "\n",
    "def update_historical_data_file(file_path: str, new_data_df: pd.DataFrame):\n",
    "    \"\"\"Lê, atualiza e salva o arquivo Parquet com os dados históricos consolidados.\"\"\"\n",
    "    print(f\"\\nAtualizando arquivo de dados históricos em: {file_path}\")\n",
    "    try:\n",
    "        historical_df = pd.read_parquet(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Arquivo Parquet não encontrado. Um novo será criado.\")\n",
    "        historical_df = pd.DataFrame()\n",
    "\n",
    "    combined_df = pd.concat([historical_df, new_data_df], ignore_index=True)\n",
    "    combined_df.drop_duplicates(subset=['ticker', 'date'], keep='first', inplace=True)\n",
    "    combined_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    combined_df.to_parquet(file_path)\n",
    "    print(\"Arquivo Parquet atualizado com sucesso.\")\n",
    "\n",
    "\n",
    "def upload_to_google_sheets(suno_df: pd.DataFrame):\n",
    "    \"\"\"Autentica e envia os dados da carteira para a planilha do Google.\"\"\"\n",
    "    print(\"\\nIniciando upload para o Google Sheets...\")\n",
    "    try:\n",
    "        creds = ServiceAccountCredentials.from_json_keyfile_name(GSPREAD_CREDENTIALS_PATH, GSPREAD_SCOPES)\n",
    "        client = gspread.authorize(creds)\n",
    "        \n",
    "        worksheet = client.open_by_key(GOOGLE_SHEETS_KEY).worksheet(GSHEET_WORKSHEET_NAME)\n",
    "\n",
    "        d2g.upload(suno_df,\n",
    "                   GOOGLE_SHEETS_KEY,\n",
    "                   GSHEET_WORKSHEET_NAME,\n",
    "                   credentials=creds,\n",
    "                   row_names=False,\n",
    "                   clean=True) # O parâmetro 'clean=True' já limpa a planilha antes de inserir.\n",
    "\n",
    "        # Upload da data de atualização\n",
    "        now_str = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        update_df = pd.DataFrame({'ultima_atualizacao': [now_str]})\n",
    "        \n",
    "        d2g.upload(update_df,\n",
    "                   GOOGLE_SHEETS_KEY,\n",
    "                   GSHEET_WORKSHEET_NAME,\n",
    "                   credentials=creds,\n",
    "                   start_cell='L1',\n",
    "                   col_names=True,\n",
    "                   row_names=False,\n",
    "                   clean=False) # clean=False aqui para não apagar os outros dados\n",
    "\n",
    "        print(\"Upload para Google Sheets concluído com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro durante o upload para o Google Sheets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d139b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando scraping da carteira Suno FIIs...\n",
      "Scraping finalizado. 22 FIIs encontrados.\n",
      "\n",
      "Iniciando a busca de dados históricos de cotações...\n",
      " -> Sucesso! 22 registros encontrados para TRXF11.\n",
      " -> Sucesso! 21 registros encontrados para BTLG11.\n",
      " -> Sucesso! 22 registros encontrados para RECR11.\n",
      " -> Sucesso! 22 registros encontrados para GARE11.\n",
      " -> Sucesso! 22 registros encontrados para VGIP11.\n",
      " -> Sucesso! 21 registros encontrados para XPML11.\n",
      " -> Sucesso! 22 registros encontrados para HGRU11.\n",
      " -> Sucesso! 21 registros encontrados para VISC11.\n",
      " -> Sucesso! 21 registros encontrados para RBRY11.\n",
      " -> Sucesso! 21 registros encontrados para FATN11.\n",
      " -> Sucesso! 21 registros encontrados para KNUQ11.\n",
      " -> Sucesso! 21 registros encontrados para MCCI11.\n",
      " -> Sucesso! 21 registros encontrados para PMLL11.\n",
      " -> Sucesso! 21 registros encontrados para XPLG11.\n",
      " -> Sucesso! 22 registros encontrados para KNRI11.\n",
      " -> Sucesso! 21 registros encontrados para VRTA11.\n",
      " -> Sucesso! 22 registros encontrados para IRDM11.\n",
      " -> Sucesso! 22 registros encontrados para BRCO11.\n",
      " -> Sucesso! 21 registros encontrados para TGAR11.\n",
      " -> Sucesso! 22 registros encontrados para PVBI11.\n",
      " -> Sucesso! 22 registros encontrados para HGLG11.\n",
      " -> Sucesso! 22 registros encontrados para LVBI11.\n",
      "\n",
      "Download de dados históricos concluído!\n",
      "\n",
      "Atualizando arquivo de dados históricos em: C:\\Users\\Guilherme\\My Drive\\Controles\\Fiis\\cotacaohistorica.parquet\n",
      "Arquivo Parquet atualizado com sucesso.\n",
      "\n",
      "Iniciando upload para o Google Sheets...\n",
      "Upload para Google Sheets concluído com sucesso.\n",
      "\n",
      "Finalizando o WebDriver.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Função principal que orquestra a execução do script.\"\"\"\n",
    "    driver = setup_webdriver()\n",
    "    try:\n",
    "        # 1. Obter dados da carteira Suno\n",
    "        suno_portfolio_df = scrape_suno_portfolio(driver)\n",
    "        \n",
    "        if suno_portfolio_df.empty:\n",
    "            print(\"Nenhum dado foi extraído da Suno. Encerrando o script.\")\n",
    "            return\n",
    "\n",
    "        # 2. Obter cotações históricas\n",
    "        tickers = suno_portfolio_df['ticker'].tolist()\n",
    "        historical_prices_df = fetch_historical_prices(tickers)\n",
    "        \n",
    "        # 3. Atualizar arquivo Parquet local\n",
    "        if not historical_prices_df.empty:\n",
    "            update_historical_data_file(PARQUET_FILE_PATH, historical_prices_df)\n",
    "        else:\n",
    "            print(\"\\nNenhum dado histórico foi baixado. O arquivo Parquet não será atualizado.\")\n",
    "\n",
    "        # 4. Enviar dados para o Google Sheets\n",
    "        upload_to_google_sheets(suno_portfolio_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro inesperado na execução principal: {e}\")\n",
    "    finally:\n",
    "        print(\"\\nFinalizando o WebDriver.\")\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
