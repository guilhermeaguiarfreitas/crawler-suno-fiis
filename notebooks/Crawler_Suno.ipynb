{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73abf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from df2gspread import df2gspread as d2g\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Suprime todos os warnings para uma saída mais limpa\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31de3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURAÇÕES GERAIS (carregadas a partir do arquivo .env)\n",
    "# ==============================================================================\n",
    "# --- Credenciais e Acessos ---\n",
    "SUNO_USERNAME = os.getenv('SUNO_USERNAME')\n",
    "SUNO_PASSWORD = os.getenv('SUNO_PASSWORD')\n",
    "BRAPI_TOKEN = os.getenv('BRAPI_TOKEN')\n",
    "GOOGLE_SHEETS_KEY = os.getenv('GOOGLE_SHEETS_KEY')\n",
    "GSPREAD_CREDENTIALS_PATH = os.getenv('GSPREAD_CREDENTIALS_PATH')\n",
    "GSHEET_WORKSHEET_NAME = 'Carteira_Suno'\n",
    "\n",
    "# --- Configurações do MinIO ---\n",
    "MINIO_ENDPOINT = os.getenv('MINIO_ENDPOINT')\n",
    "MINIO_ACCESS_KEY = os.getenv('MINIO_ACCESS_KEY')\n",
    "MINIO_SECRET_KEY = os.getenv('MINIO_SECRET_KEY')\n",
    "MINIO_BUCKET = os.getenv('MINIO_BUCKET')\n",
    "PARQUET_OBJECT_NAME = os.getenv('PARQUET_OBJECT_NAME')\n",
    "\n",
    "# --- URLs e Endpoints ---\n",
    "SUNO_LOGIN_URL = 'https://login.suno.com.br/entrar/cef02de7-1e5a-4b0e-9f41-04e9278aa2d7/'\n",
    "SUNO_FIIS_URL = 'https://investidor.suno.com.br/carteiras/fiis'\n",
    "BRAPI_BASE_URL = 'https://brapi.dev/api/quote'\n",
    "\n",
    "# --- Configurações do Google API ---\n",
    "GSPREAD_SCOPES = [\n",
    "    'https://spreadsheets.google.com/feeds',\n",
    "    'https://www.googleapis.com/auth/drive',\n",
    "    'https://www.googleapis.com/auth/drive.file',\n",
    "    'https://www.googleapis.com/auth/spreadsheets'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ce1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_webdriver() -> webdriver.Chrome:\n",
    "    \"\"\"Configura e inicializa o WebDriver do Selenium.\"\"\"\n",
    "    sys.path.insert(0, \"/usr/lib/chromium-driver/chromedriver\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    arguments = [\n",
    "        '--headless', '--no-sandbox', '--disable-dev-shm-usage',\n",
    "        '--start-maximized', '--window-size=1920,1080', '--disable-gpu',\n",
    "        '--ignore-certificate-errors', '--disable-extensions',\n",
    "        'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'\n",
    "    ]\n",
    "    for arg in arguments:\n",
    "        chrome_options.add_argument(arg)\n",
    "        \n",
    "    return webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        \n",
    "def scrape_suno_portfolio(driver: webdriver.Chrome) -> pd.DataFrame:\n",
    "    \"\"\"Realiza o login no site da Suno e extrai os dados da carteira de FIIs.\"\"\"\n",
    "    print(\"Iniciando scraping da carteira Suno FIIs...\")\n",
    "    driver.get(SUNO_LOGIN_URL)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"user_email\"))).send_keys(SUNO_USERNAME)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"user_password\"))).send_keys(SUNO_PASSWORD)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"login_button\"))).click()\n",
    "    \n",
    "    WebDriverWait(driver, 25).until(EC.url_contains('home'))\n",
    "    driver.get(SUNO_FIIS_URL)\n",
    "    \n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'tbody.ant-table-tbody')))\n",
    "    time.sleep(2)  # Mantido para garantir a renderização completa da página.\n",
    "\n",
    "    html = driver.execute_script(\"return document.body.outerHTML;\")\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    table_body = soup.find('tbody')\n",
    "    if not table_body:\n",
    "        raise ValueError(\"Tabela de FIIs não encontrada na página.\")\n",
    "        \n",
    "    list_td = table_body.find_all('td')\n",
    "    \n",
    "    scraped_data = []\n",
    "    # A lógica de iteração (índices fixos) foi mantida para não alterar o resultado.\n",
    "    i = 11\n",
    "    step = i - 1\n",
    "    while True:\n",
    "        try:\n",
    "            fii = {\n",
    "                'ticker': list_td[i].text.replace('Ver relatórios', ''),\n",
    "                'setor/tipo': list_td[i+1].text,\n",
    "                'dy esperado': list_td[i+2].text,\n",
    "                'início': list_td[i+3].text[-10:],\n",
    "                'preço de entrada ajustado': list_td[i+3].text[:-10],\n",
    "                'preço atual': list_td[i+4].text.split(',')[0] + ',' + list_td[i+4].text.split(',')[1][:-1].replace('-', ''),\n",
    "                'preço teto': list_td[i+5].text,\n",
    "                'alocação': list_td[i+6].text,\n",
    "                'rentabilidade': list_td[i+7].text,\n",
    "                'viés': list_td[i+8].text\n",
    "            }\n",
    "            scraped_data.append(fii)\n",
    "            i += step\n",
    "        except IndexError:\n",
    "            break\n",
    "            \n",
    "    print(f\"Scraping finalizado. {len(scraped_data)} FIIs encontrados.\")\n",
    "    return pd.DataFrame(scraped_data)\n",
    "\n",
    "\n",
    "def fetch_historical_prices(tickers: list) -> pd.DataFrame:\n",
    "    \"\"\"Busca o histórico de preços para uma lista de tickers usando a API Brapi.\"\"\"\n",
    "    print(\"\\nIniciando a busca de dados históricos de cotações...\")\n",
    "    all_dataframes = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        url = f\"{BRAPI_BASE_URL}/{ticker}?range=1mo&interval=1d&token={BRAPI_TOKEN}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data_prices = response.json()\n",
    "            \n",
    "            historical_list = data_prices['results'][0]['historicalDataPrice']\n",
    "            df_fii = pd.DataFrame(historical_list)\n",
    "            df_fii['ticker'] = ticker\n",
    "            all_dataframes.append(df_fii)\n",
    "            print(f\" -> Sucesso! {len(df_fii)} registros encontrados para {ticker}.\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\" -> ERRO de requisição para {ticker}: {e}\")\n",
    "        except (KeyError, IndexError):\n",
    "            print(f\" -> ERRO: Ticker '{ticker}' não encontrado ou sem dados na API.\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    if not all_dataframes:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    hist_1m = pd.concat(all_dataframes, ignore_index=True)\n",
    "    hist_1m['date'] = pd.to_datetime(hist_1m['date'], unit='s').dt.date\n",
    "    \n",
    "    print(\"\\nDownload de dados históricos concluído!\")\n",
    "    return hist_1m[['ticker', 'date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "\n",
    "def setup_minio_client(minio_config):\n",
    "    \"\"\"Configura e retorna o cliente para se conectar ao Minio.\"\"\"\n",
    "    if not all(minio_config.values()):\n",
    "        print(\"ERRO: Configurações do Minio incompletas. Verifique o arquivo .env\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Cria o cliente S3\n",
    "        client = boto3.client(\n",
    "            's3',\n",
    "            endpoint_url=minio_config['endpoint'],\n",
    "            aws_access_key_id=minio_config['access_key'],\n",
    "            aws_secret_access_key=minio_config['secret_key'],\n",
    "            config=Config(signature_version='s3v4')\n",
    "        )\n",
    "        # Verifica se o bucket existe, senão cria\n",
    "        try:\n",
    "            client.head_bucket(Bucket=minio_config['bucket'])\n",
    "        except ClientError:\n",
    "            print(f\"Bucket '{minio_config['bucket']}' não encontrado. Criando...\")\n",
    "            client.create_bucket(Bucket=minio_config['bucket'])\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO: Não foi possível conectar ao Minio. Detalhe: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_parquet_in_minio(new_data_df: pd.DataFrame):\n",
    "    \"\"\"Lê, atualiza e salva o arquivo Parquet no MinIO usando boto3.\"\"\"\n",
    "    \n",
    "    # Monta o dicionário de configuração a partir das variáveis de ambiente\n",
    "    minio_config = {\n",
    "        'endpoint': MINIO_ENDPOINT,\n",
    "        'access_key': MINIO_ACCESS_KEY,\n",
    "        'secret_key': MINIO_SECRET_KEY,\n",
    "        'bucket': MINIO_BUCKET\n",
    "    }\n",
    "    \n",
    "    s3_client = setup_minio_client(minio_config)\n",
    "    \n",
    "    if not s3_client:\n",
    "        print(\"-> Cliente Minio não configurado. Pulando salvamento.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\nAtualizando arquivo Parquet no MinIO (Bucket: {MINIO_BUCKET})...\")\n",
    "    \n",
    "    try:\n",
    "        # 1. LER o objeto existente do MinIO\n",
    "        response = s3_client.get_object(Bucket=MINIO_BUCKET, Key=PARQUET_OBJECT_NAME)\n",
    "        # Ler o conteúdo do objeto em um buffer de memória\n",
    "        buffer = BytesIO(response['Body'].read())\n",
    "        historical_df = pd.read_parquet(buffer)\n",
    "        print(\"Arquivo Parquet existente lido do MinIO.\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        # Se o erro for 'NoSuchKey', significa que o arquivo não existe (primeira execução)\n",
    "        if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "            print(\"Arquivo Parquet não encontrado no MinIO. Um novo será criado.\")\n",
    "            historical_df = pd.DataFrame()\n",
    "        else:\n",
    "            # Para outros erros, lança a exceção\n",
    "            print(f\"ERRO ao ler do MinIO: {e}\")\n",
    "            raise\n",
    "\n",
    "    # 2. COMBINAR os dataframes (lógica mantida)\n",
    "    combined_df = pd.concat([historical_df, new_data_df], ignore_index=True)\n",
    "    combined_df.drop_duplicates(subset=['ticker', 'date'], keep='first', inplace=True)\n",
    "    combined_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 3. ESCREVER o novo dataframe de volta para o MinIO\n",
    "    # Converter o dataframe para o formato parquet em um buffer de memória\n",
    "    out_buffer = BytesIO()\n",
    "    combined_df.to_parquet(out_buffer, index=False)\n",
    "    \n",
    "    # Enviar os bytes do buffer para o MinIO\n",
    "    s3_client.put_object(\n",
    "        Bucket=MINIO_BUCKET, \n",
    "        Key=PARQUET_OBJECT_NAME, \n",
    "        Body=out_buffer.getvalue()\n",
    "    )\n",
    "    print(\"Arquivo Parquet atualizado com sucesso no MinIO.\")\n",
    "\n",
    "def upload_to_google_sheets(suno_df: pd.DataFrame):\n",
    "    \"\"\"Autentica e envia os dados da carteira para a planilha do Google.\"\"\"\n",
    "    print(\"\\nIniciando upload para o Google Sheets...\")\n",
    "    try:\n",
    "        creds = ServiceAccountCredentials.from_json_keyfile_name(GSPREAD_CREDENTIALS_PATH, GSPREAD_SCOPES)\n",
    "        client = gspread.authorize(creds)\n",
    "        \n",
    "        worksheet = client.open_by_key(GOOGLE_SHEETS_KEY).worksheet(GSHEET_WORKSHEET_NAME)\n",
    "\n",
    "        d2g.upload(suno_df,\n",
    "                   GOOGLE_SHEETS_KEY,\n",
    "                   GSHEET_WORKSHEET_NAME,\n",
    "                   credentials=creds,\n",
    "                   row_names=False,\n",
    "                   clean=True) # O parâmetro 'clean=True' já limpa a planilha antes de inserir.\n",
    "\n",
    "        # Upload da data de atualização\n",
    "        now_str = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        update_df = pd.DataFrame({'ultima_atualizacao': [now_str]})\n",
    "        \n",
    "        d2g.upload(update_df,\n",
    "                   GOOGLE_SHEETS_KEY,\n",
    "                   GSHEET_WORKSHEET_NAME,\n",
    "                   credentials=creds,\n",
    "                   start_cell='L1',\n",
    "                   col_names=True,\n",
    "                   row_names=False,\n",
    "                   clean=False) # clean=False aqui para não apagar os outros dados\n",
    "\n",
    "        print(\"Upload para Google Sheets concluído com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro durante o upload para o Google Sheets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d139b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando scraping da carteira Suno FIIs...\n",
      "Scraping finalizado. 22 FIIs encontrados.\n",
      "\n",
      "Iniciando a busca de dados históricos de cotações...\n",
      " -> Sucesso! 22 registros encontrados para RBRY11.\n",
      " -> Sucesso! 22 registros encontrados para TRXF11.\n",
      " -> Sucesso! 23 registros encontrados para BTLG11.\n",
      " -> Sucesso! 23 registros encontrados para XPML11.\n",
      " -> Sucesso! 22 registros encontrados para GARE11.\n",
      " -> Sucesso! 23 registros encontrados para MCCI11.\n",
      " -> Sucesso! 23 registros encontrados para HGRU11.\n",
      " -> Sucesso! 23 registros encontrados para RECR11.\n",
      " -> Sucesso! 23 registros encontrados para KNUQ11.\n",
      " -> Sucesso! 23 registros encontrados para IRDM11.\n",
      " -> Sucesso! 22 registros encontrados para PMLL11.\n",
      " -> Sucesso! 22 registros encontrados para FATN11.\n",
      " -> Sucesso! 22 registros encontrados para VISC11.\n",
      " -> Sucesso! 23 registros encontrados para TGAR11.\n",
      " -> Sucesso! 22 registros encontrados para KNRI11.\n",
      " -> Sucesso! 23 registros encontrados para VGIP11.\n",
      " -> Sucesso! 22 registros encontrados para XPLG11.\n",
      " -> Sucesso! 22 registros encontrados para BRCO11.\n",
      " -> Sucesso! 22 registros encontrados para VRTA11.\n",
      " -> Sucesso! 22 registros encontrados para PVBI11.\n",
      " -> Sucesso! 23 registros encontrados para HGLG11.\n",
      " -> Sucesso! 22 registros encontrados para LVBI11.\n",
      "\n",
      "Download de dados históricos concluído!\n",
      "\n",
      "Atualizando arquivo Parquet no MinIO (Bucket: gold-layer)...\n",
      "Arquivo Parquet existente lido do MinIO.\n",
      "Arquivo Parquet atualizado com sucesso no MinIO.\n",
      "\n",
      "Iniciando upload para o Google Sheets...\n",
      "Upload para Google Sheets concluído com sucesso.\n",
      "\n",
      "Finalizando o WebDriver.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Função principal que orquestra a execução do script.\"\"\"\n",
    "    driver = setup_webdriver()\n",
    "    try:\n",
    "        # 1. Obter dados da carteira Suno\n",
    "        suno_portfolio_df = scrape_suno_portfolio(driver)\n",
    "        \n",
    "        if suno_portfolio_df.empty:\n",
    "            print(\"Nenhum dado foi extraído da Suno. Encerrando o script.\")\n",
    "            return\n",
    "\n",
    "        # 2. Obter cotações históricas\n",
    "        tickers = suno_portfolio_df['ticker'].tolist()\n",
    "        historical_prices_df = fetch_historical_prices(tickers)\n",
    "        \n",
    "        # 3. Atualizar arquivo Parquet no data lake\n",
    "        if not historical_prices_df.empty:\n",
    "            update_parquet_in_minio(historical_prices_df)\n",
    "        else:\n",
    "            print(\"\\nNenhum dado histórico foi baixado. O arquivo no MinIO não será atualizado.\")\n",
    "\n",
    "        # 4. Enviar dados para o Google Sheets\n",
    "        upload_to_google_sheets(suno_portfolio_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro inesperado na execução principal: {e}\")\n",
    "    finally:\n",
    "        print(\"\\nFinalizando o WebDriver.\")\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
